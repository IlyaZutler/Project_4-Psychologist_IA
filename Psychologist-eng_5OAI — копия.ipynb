{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domashniy\\AppData\\Local\\Temp\\ipykernel_31340\\3544470558.py:33: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4\", temperature=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting session for: Ilya      \n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: hey yesterday I was in the restaurant\n",
      "Recording stopped.\n",
      "Program response: Ilya, it sounds like you had another visit to a restaurant. Can you share how this experience was different or similar to the previous one with your family?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: pretty good my elephant and my zebra of\n",
      "Could not understand the audio. Please speak clearly.\n",
      "You said: pipe to my sons were upset a little bit\n",
      "You said: no I'm just worrying is it good for my zebra and elephant\n",
      "Recording stopped.\n",
      "Program response: Ilya, it's interesting to hear about your elephant and zebra. Why do you think your sons were upset? And what makes you worry about your zebra and elephant?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: my sons were upset\n",
      "You said: children's\n",
      "You said: and the baby\n",
      "You said: doing the children's in the restaurants\n",
      "You said: no conversation with anything else\n",
      "Recording stopped.\n",
      "Program response: Ilya, it seems like your sons might have been upset because of the children's activities in the restaurant. Can you tell me more about that? Also, what specific concerns do you have about your zebra and elephant?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: my Ze\n",
      "You said: I love\n",
      "You said: it's white and black and white and black and white and black and white and black and white and black and so on\n",
      "You said: he's not black he's not white\n",
      "Could not understand the audio. Please speak clearly.\n",
      "You said: is gray gray gray gray gray gray gray gray gray gray gray gray gray gray\n",
      "Recording stopped.\n",
      "Program response: Ilya, it seems like you have a deep affection for your zebra. The color gray you mentioned, is it something that bothers you or is it something you find unique about your zebra?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: oh my\n",
      "You said: unique\n",
      "Recording stopped.\n",
      "Program response: Ilya, it sounds like you find your zebra's gray color unique. Can you tell me more about why you find it unique?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Session ended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domashniy\\AppData\\Local\\Temp\\ipykernel_31340\\3544470558.py:242: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm([system_message, human_message])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation summary: The conversation is between a patient named Ilya and a psychologist. Ilya talks about a recent visit to a restaurant and mentions his elephant and zebra, which seem to be metaphorical or symbolic. He expresses concern for them and shares that his sons were upset during the restaurant visit. The psychologist tries to understand more about these concerns and the reasons for his sons' upset. Ilya also talks about his love for his zebra, particularly noting its gray color, which he finds unique. The psychologist encourages Ilya to share more about why he finds the zebra's color unique.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import pyodbc\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import torch\n",
    "import keyboard\n",
    "import threading\n",
    "import time\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# API key for OpenAI\n",
    "OPENAI_API_KEY = ''\n",
    "\n",
    "# Connecting to SQL Server database\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};'\n",
    "    'SERVER=DESKTOP-SPMU70G\\SQLEXPRESS;'\n",
    "    'DATABASE=Psychologist;'\n",
    "    'UID=DESKTOP-SPMU70G\\domashniy;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Model for generating text embeddings (e.g., Sentence-BERT)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define LLM using OpenAI\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4\", temperature=0.5)\n",
    "\n",
    "# Recording flag\n",
    "recording = False\n",
    "# Session finish flag\n",
    "finish_session = False\n",
    "\n",
    "def stop_recording():\n",
    "    global recording\n",
    "    keyboard.wait('f')  # Wait for the 'f' key press\n",
    "    time.sleep(0.1)  # Small delay before stopping recording\n",
    "    recording = False  # Set the recording flag to false\n",
    "\n",
    "def finish_session_function():\n",
    "    global finish_session\n",
    "    while not finish_session:\n",
    "        if keyboard.is_pressed('q'):  # Check for 'q' key press\n",
    "            finish_session = True  # Set the session finish flag\n",
    "        time.sleep(0.1)  # Short pause to reduce CPU load\n",
    "\n",
    "# Speech recognition function with keyboard input\n",
    "def recognize_speech():\n",
    "    global recording, finish_session\n",
    "    patient_query = \"\"\n",
    "    r = sr.Recognizer()\n",
    "    print(\"Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\")\n",
    "\n",
    "    # Start a thread for session termination\n",
    "    threading.Thread(target=finish_session_function, daemon=True).start()\n",
    "\n",
    "    while not finish_session:\n",
    "        # Check if 's' key is pressed\n",
    "        if keyboard.is_pressed('s') and not recording:  # If 's' is pressed and not already recording\n",
    "            recording = True  # Set the recording flag to start\n",
    "            print(\"Recording. Speak...\")\n",
    "            threading.Thread(target=stop_recording, daemon=True).start()  # Start a thread to stop recording\n",
    "\n",
    "        if recording:  # If recording is active, process audio\n",
    "            with sr.Microphone() as source:\n",
    "                r.adjust_for_ambient_noise(source)  # Adjust for ambient noise\n",
    "                full_text = []\n",
    "\n",
    "                while recording and not finish_session:  # Also check the session finish flag\n",
    "                    try:\n",
    "                        # Start recording\n",
    "                        audio = r.listen(source, timeout=None)\n",
    "\n",
    "                        # Convert recording to text\n",
    "                        text = r.recognize_google(audio, language=\"en-US\")\n",
    "                        print(f\"You said: {text}\")\n",
    "                        full_text.append(text)  # Append recognized text to the list\n",
    "                        \n",
    "                    except sr.UnknownValueError:\n",
    "                        print(\"Could not understand the audio. Please speak clearly.\")\n",
    "                    except sr.RequestError as e:\n",
    "                        print(f\"Service error; {e}\")\n",
    "                        break\n",
    "\n",
    "                print(\"Recording stopped.\")\n",
    "                recording = False  # Explicitly reset the flag in case it wasn't reset\n",
    "                patient_query = ' '.join(full_text)  # Return the combined text\n",
    "                return patient_query  # Return the combined text\n",
    "    \n",
    "    return patient_query\n",
    "\n",
    "# Function to generate an audio response\n",
    "def text_to_speech(text):\n",
    "    tts = gTTS(text=text, lang='en')  # Changed 'ru' to 'en'\n",
    "    tts.save(\"response_en.mp3\")\n",
    "    audio = AudioSegment.from_mp3(\"response_en.mp3\")\n",
    "    play(audio)\n",
    "\n",
    "# Function to find the most recent completed conversation (previous_talk)\n",
    "def find_previous_talk(patient_id):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT TOP 1 Record FROM Talks\n",
    "        WHERE ID_Patient = ? \n",
    "        ORDER BY Date_Time DESC\n",
    "    \"\"\", (patient_id,))\n",
    "    previous_talk = cursor.fetchone()\n",
    "    return previous_talk[0] if previous_talk else \"\"\n",
    "\n",
    "# Function to update the session record with patient query\n",
    "def update_session_record_query(patient_query, session_record):\n",
    "    session_record += f\"Patient said: {patient_query}. \"    \n",
    "    return session_record\n",
    "\n",
    "# Function to update the session record with program response\n",
    "def update_session_record_response(program_response, session_record):\n",
    "    session_record += f\"Psychologist responded: {program_response}. \"\n",
    "    return session_record\n",
    "\n",
    "# Function to find the most similar and most dissimilar conversations\n",
    "def find_similar_talks(patient_id, query):\n",
    "    # Fetch all embeddings and summaries for the given patient from the database\n",
    "    cursor.execute(\"SELECT Embedding, Summary FROM Talks WHERE ID_Patient = ?\", (patient_id,))\n",
    "    past_talks = cursor.fetchall()\n",
    "    \n",
    "    # Generate the embedding for the current query\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    # Variables to store the most similar and most dissimilar talks\n",
    "    most_similar_talk = None\n",
    "    most_dissimilar_talk = None\n",
    "    \n",
    "    highest_similarity = float('-inf')  # Initialize with a very low value\n",
    "    lowest_similarity = float('inf')    # Initialize with a very high value\n",
    "\n",
    "    # Loop through each saved embedding from the database\n",
    "    for talk in past_talks:\n",
    "        talk_embedding_str = talk[0]  # Extract the embedding as a string\n",
    "        talk_summary = talk[1]        # Extract the corresponding summary\n",
    "        \n",
    "        # Convert the embedding from a string back to a tensor\n",
    "        talk_embedding = torch.tensor(list(map(float, talk_embedding_str.split(','))))\n",
    "        \n",
    "        # Compute cosine similarity between the current query and the saved embeddings\n",
    "        similarity = util.pytorch_cos_sim(query_embedding, talk_embedding).item()\n",
    "        \n",
    "        # Check if this is the most similar talk so far\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            most_similar_talk = talk_summary\n",
    "        \n",
    "        # Check if this is the most dissimilar talk so far\n",
    "        if similarity < lowest_similarity:\n",
    "            lowest_similarity = similarity\n",
    "            most_dissimilar_talk = talk_summary\n",
    "    \n",
    "    # Return the summaries of the most similar and most dissimilar talks\n",
    "    return most_similar_talk, most_dissimilar_talk\n",
    "\n",
    "# Function to retrieve patient information from the database\n",
    "def get_patient_info(patient_id):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT ID_Patient, Name, Date_of_birth, Sex, Additional_datas, Condition \n",
    "        FROM Patients \n",
    "        WHERE ID_Patient = ?\n",
    "    \"\"\", (patient_id,))\n",
    "    patient_info = cursor.fetchone()\n",
    "    if patient_info:\n",
    "        return {\n",
    "            \"ID_Patient\": patient_info[0],\n",
    "            \"Name\": patient_info[1],\n",
    "            \"Date_of_birth\": patient_info[2],\n",
    "            \"Sex\": patient_info[3],\n",
    "            \"Additional_datas\": patient_info[4],\n",
    "            \"Condition\": patient_info[5]\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to save the conversation data, including the embedding, into the database\n",
    "def save_talk(patient_id, text, summary, sentiment):\n",
    "    embedding = model.encode(summary, convert_to_tensor=True)\n",
    "    embedding_str = ','.join(map(str, embedding.tolist()))\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Talks (ID_Patient, Date_Time, Record, Summary, Sentiment, Embedding)\n",
    "        VALUES (?, GETDATE(), ?, ?, ?, ?)\n",
    "    \"\"\", (patient_id, text, summary, sentiment, embedding_str))\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "# Function to generate a response using LLM and langchain-groq\n",
    "def generate_response_llm(session_record, previous_talk, similar_talk, dissimilar_talk, patient_info):\n",
    "    system_message = SystemMessage(content=f\"\"\"\n",
    "        You are a qualified and concise psychologist, helping the Patient discuss their problems.\n",
    "        The conversation consists of several questions and answers.\n",
    "            \n",
    "        Patient information:\n",
    "            Name: {patient_info['Name']},\n",
    "            Date of birth: {patient_info['Date_of_birth']},\n",
    "            Sex: {patient_info['Sex']},\n",
    "            Additional data: {patient_info['Additional_datas']},\n",
    "            Condition: {patient_info['Condition']}.\n",
    "\n",
    "        Here is the previous conversation with the Patient: {previous_talk or 'No previous conversation'}. \n",
    "        Here is the summary of the most similar conversation with the Patient: {similar_talk or 'No similar conversation'}.\n",
    "        Here is the summary of the most dissimilar conversation with the Patient: {dissimilar_talk or 'No dissimilar conversation'}.\n",
    "\n",
    "        You will receive for anser a record of the current conversation - the Patient's last question at the end.\n",
    "\n",
    "        Do not greet the Patient every time you answer a question.\n",
    "        Do not repeat 'and what do you think it might mean for you'\n",
    "        Do not call the interlocutor the Patient. Use the Patient Name but not all the time.\n",
    "        Do not repeat the interlocutor's question before answering.\n",
    "        Avoid long responses. Ask clarifying questions.\n",
    "        Analyze the entire conversation from the very beginning, and not just the Patient's last phrase,\n",
    "        Pay attention to .\n",
    "        Pay attention to all the information about the Patient and previous conversations - You can mention this in your questions.\n",
    "    \"\"\")\n",
    "        \n",
    "    human_message = HumanMessage(content=f\"\"\"\n",
    "        Here is the current conversation record with the Patient: {session_record}.\n",
    "    \"\"\")\n",
    "    \n",
    "    # response = llm.invoke([system_message, human_message])\n",
    "    try:\n",
    "        response = llm.invoke([system_message, human_message])\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при вызове LLM: {e}\")      \n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Function to generate a summary at the end of the conversation\n",
    "def generate_summary(session_record):\n",
    "    system_message = SystemMessage(content=\"You are a qualified psychologist. Create a brief summary of your conversation whith Patient.\")\n",
    "    human_message = HumanMessage(content=f\"Conversation: {session_record}.\")\n",
    "    \n",
    "    response = llm([system_message, human_message])\n",
    "    return response.content\n",
    "\n",
    "# Main session process\n",
    "def main(patient_id):\n",
    "    global finish_session\n",
    "    previous_talk = find_previous_talk(patient_id)\n",
    "    session_record = \"\"  \n",
    "    response_text = \"\"  \n",
    "\n",
    "    # Запускаем поток для завершения сессии\n",
    "    threading.Thread(target=finish_session_function, daemon=True).start()\n",
    "\n",
    "    # Retrieve patient info and pass it to the LLM\n",
    "    patient_info = get_patient_info(patient_id)\n",
    "    if not patient_info:\n",
    "        print(\"Patient information not found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Starting session for: {patient_info['Name']}\")\n",
    "\n",
    "    Start_Talk = True\n",
    "    similar_talk = dissimilar_talk = \"\"\n",
    "\n",
    "    while True:        \n",
    "        patient_query = recognize_speech()\n",
    "        if finish_session:  \n",
    "            print(\"Session ended.\")\n",
    "            summary = generate_summary(session_record)\n",
    "            print(f\"Conversation summary: {summary}\")\n",
    "            save_talk(patient_id, session_record, summary, \"Neutral\")\n",
    "            break\n",
    "\n",
    "        session_record = update_session_record_query(patient_query, session_record)\n",
    "\n",
    "        if Start_Talk:\n",
    "            similar_talk, dissimilar_talk = find_similar_talks(patient_id, session_record)\n",
    "            if similar_talk and dissimilar_talk:\n",
    "                similar_talk = similar_talk\n",
    "                dissimilar_talk = dissimilar_talk\n",
    "            else:\n",
    "                similar_talk = dissimilar_talk = \"\"\n",
    "            \n",
    "            Start_Talk = False\n",
    "\n",
    "        # Pass patient info to LLM along with the conversation context\n",
    "        response_text = generate_response_llm(session_record, previous_talk, similar_talk, dissimilar_talk, patient_info)\n",
    "        print(f\"Program response: {response_text}\")\n",
    "\n",
    "        session_record = update_session_record_response(response_text, session_record)\n",
    "\n",
    "        text_to_speech(response_text)\n",
    "\n",
    "# Entry point for the program\n",
    "if __name__ == \"__main__\":\n",
    "    patient_id = input(\"Enter patient ID: \")\n",
    "    main(patient_id=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
