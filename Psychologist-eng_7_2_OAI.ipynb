{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for 'find_previous_talk': 0.0264  seconds.\n",
      "Starting session for: Ilya      \n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: Я вчера где-то оставил ухо не могу весь день сегодня его найти\n",
      "Execution time for 'analyze_emotion': 0.0345  seconds.\n",
      "Emotion: neutral\n",
      "Recording stopped.\n",
      "Execution time for 'find_similar_talks': 2.2015  seconds.\n",
      "Program response: Что вы имеете в виду, когда говорите, что \"оставили ухо\"?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: Куда ты его положил\n",
      "Execution time for 'analyze_emotion': 0.0093  seconds.\n",
      "Emotion: excited\n",
      "You said: я положу\n",
      "Execution time for 'analyze_emotion': 0.0070  seconds.\n",
      "Emotion: neutral\n",
      "Recording stopped.\n",
      "Program response: Как вы думаете, что может символизировать \"оставленное ухо\"?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: ухо ухо - это та часть тела которая на голове\n",
      "Execution time for 'analyze_emotion': 0.0239  seconds.\n",
      "Emotion: neutral\n",
      "Recording stopped.\n",
      "Program response: Как вы думаете, что может означать для вас потеря этой части тела?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: Ну как-то некрасиво безуха ходить\n",
      "Execution time for 'analyze_emotion': 0.0196  seconds.\n",
      "Emotion: neutral\n",
      "Recording stopped.\n",
      "Program response: Как вы думаете, что вы чувствуете из-за этой \"потери\"?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: чувствую что на меня смотрят и видит что я без уха\n",
      "Execution time for 'analyze_emotion': 0.0465  seconds.\n",
      "Emotion: calm\n",
      "Recording stopped.\n",
      "Program response: Как вы думаете, что это чувство наблюдения за вами без уха говорит о вашем внутреннем состоянии?\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Session ended.\n",
      "Conversation summary: **Summary of Conversation:**\n",
      "\n",
      "The patient expressed a metaphorical concern about losing an ear, which initially seemed literal. The psychologist explored the symbolic meaning of this \"lost ear,\" prompting the patient to reflect on feelings of self-consciousness and being observed by others. The conversation delved into the emotional impact of this perceived loss and its implications on the patient's internal state.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import pyodbc\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import torch\n",
    "import keyboard\n",
    "import threading\n",
    "import time\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import time\n",
    "import functools\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def import_llm_models():\n",
    "    # API key for OpenAI\n",
    "    OPENAI_API_KEY = '...'\n",
    "    # Define LLM using OpenAI\n",
    "    llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"ft:gpt-4o-2024-08-06:personal:psychologist-1:APyJnbej\", temperature=0.5) #gpt-4o-2024-08-06 with fine tuning\n",
    "\n",
    "    # Model for generating text embeddings (e.g., Sentence-BERT)\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    return llm, model\n",
    "\n",
    "def log_execution_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  \n",
    "        result = func(*args, **kwargs)  \n",
    "        end_time = time.time()  \n",
    "        execution_time = end_time - start_time  \n",
    "        print(f\"Execution time for '{func.__name__}': {execution_time:.4f}  seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def stop_recording():\n",
    "    global recording\n",
    "    keyboard.wait('f')  # Wait for the 'f' key press\n",
    "    time.sleep(0.1)  # Small delay before stopping recording\n",
    "    recording = False  # Set the recording flag to false\n",
    "\n",
    "def finish_session_function():\n",
    "    global finish_session\n",
    "    while not finish_session:\n",
    "        if keyboard.is_pressed('q'):  # Check for 'q' key press\n",
    "            finish_session = True  # Set the session finish flag\n",
    "        time.sleep(0.1)  # Short pause to reduce CPU load\n",
    "\n",
    "# Function to analyze emotion based on audio features\n",
    "@log_execution_time\n",
    "def analyze_emotion(audio_data, sr):\n",
    "    # Convert audio data to float32 and normalize\n",
    "    audio_data = audio_data.astype(np.float32) / np.max(np.abs(audio_data))\n",
    "    \n",
    "    # Extracting features\n",
    "    energy = np.mean(librosa.feature.rms(y=audio_data))\n",
    "    pitch, _ = librosa.piptrack(y=audio_data, sr=sr)\n",
    "    pitch_mean = np.mean(pitch[pitch > 0])\n",
    "\n",
    "    # Basic emotion classification (for demonstration purposes)\n",
    "    if energy > 0.1 and pitch_mean > 150:\n",
    "        emotion = \"excited\"\n",
    "    elif energy < 0.05:\n",
    "        emotion = \"calm\"\n",
    "    elif pitch_mean < 120:\n",
    "        emotion = \"scared\"\n",
    "    else:\n",
    "        emotion = \"neutral\"\n",
    "\n",
    "    return emotion\n",
    "\n",
    "# Speech recognition function with emotion analysis\n",
    "def recognize_speech():\n",
    "    global recording, finish_session\n",
    "    patient_query = \"\"\n",
    "    r = sr.Recognizer()\n",
    "    print(\"Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\")\n",
    "\n",
    "    while not finish_session:\n",
    "        if keyboard.is_pressed('s') and not recording:  # Start recording on 's' key press\n",
    "            recording = True\n",
    "            print(\"Recording. Speak...\")\n",
    "            threading.Thread(target=stop_recording, daemon=True).start()  # Thread to stop recording\n",
    "\n",
    "        if recording:  # Recording is active\n",
    "            with sr.Microphone() as source:\n",
    "                r.adjust_for_ambient_noise(source)\n",
    "                full_text = []\n",
    "\n",
    "                while recording and not finish_session:\n",
    "                    try:\n",
    "                        audio = r.listen(source, timeout=None)\n",
    "                        text = r.recognize_google(audio, language=\"ru-RU\")\n",
    "                        print(f\"You said: {text}\")\n",
    "                        full_text.append(text)\n",
    "                        \n",
    "                        # Convert to audio array for emotion analysis\n",
    "                        audio_data = np.frombuffer(audio.get_raw_data(), np.int16)\n",
    "                        emotion = analyze_emotion(audio_data, source.SAMPLE_RATE)\n",
    "                        print(f\"Emotion: {emotion}\")\n",
    "\n",
    "                    except sr.UnknownValueError:\n",
    "                        print(\"Could not understand the audio. Please speak clearly.\")\n",
    "                    except sr.RequestError as e:\n",
    "                        print(f\"Service error; {e}\")\n",
    "                        break\n",
    "\n",
    "                print(\"Recording stopped.\")\n",
    "                recording = False\n",
    "                patient_query = ' '.join(full_text)\n",
    "                return patient_query, emotion  # Return recognized text with emotion\n",
    "    \n",
    "    return patient_query, \"No emotion detected\"  # Default return in case of session end\n",
    "\n",
    "# Function to generate an audio response\n",
    "def text_to_speech(text):\n",
    "    tts = gTTS(text=text, lang='ru')  # Changed 'ru' to 'en'\n",
    "    tts.save(\"response.mp3\")\n",
    "    audio = AudioSegment.from_mp3(\"response.mp3\")\n",
    "    play(audio)\n",
    "\n",
    "# Function to open DB to read and write, do not fogget to close DB - 0.6867  seconds \n",
    "def open_db():\n",
    "    # Connecting to SQL Server database\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={SQL Server};'\n",
    "        'SERVER=DESKTOP-SPMU70G\\SQLEXPRESS;'\n",
    "        'DATABASE=Psychologist;'\n",
    "        'UID=DESKTOP-SPMU70G\\domashniy;'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# Function to find the most recent completed conversation (previous_talk)\n",
    "@log_execution_time\n",
    "def find_previous_talk(patient_id):\n",
    "    # Connecting to SQL Server database\n",
    "    conn = open_db()\n",
    "    cursor = conn.cursor()      \n",
    "       \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT TOP 1 Record FROM Talks\n",
    "        WHERE ID_Patient = ? \n",
    "        ORDER BY Date_Time DESC\n",
    "    \"\"\", (patient_id,))\n",
    "    previous_talk = cursor.fetchone()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return previous_talk[0] if previous_talk else \"\"\n",
    "\n",
    "# Function to update the session record with patient query\n",
    "def update_session_record_query(patient_query, session_record):\n",
    "    session_record += f\"Patient said: {patient_query}. \"    \n",
    "    return session_record\n",
    "\n",
    "# Function to update the session record with program response\n",
    "def update_session_record_response(program_response, session_record):\n",
    "    session_record += f\"Psychologist responded: {program_response}. \"\n",
    "    return session_record\n",
    "\n",
    "# Function to find the most similar and most dissimilar conversations 2.2015  seconds\n",
    "@log_execution_time\n",
    "def find_similar_talks(llm, model, patient_id, query):\n",
    "    # Connecting to SQL Server database\n",
    "    conn = open_db()\n",
    "    cursor = conn.cursor()       \n",
    "            \n",
    "    # Fetch all embeddings and summaries for the given patient from the database\n",
    "    cursor.execute(\"SELECT Embedding, Summary FROM Talks WHERE ID_Patient = ?\", (patient_id,))\n",
    "    past_talks = cursor.fetchall()\n",
    "    \n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    # Generate the embedding for the current query\n",
    "    query_s = generate_summary(llm, query)\n",
    "    query_embedding = model.encode(query_s, convert_to_tensor=True)\n",
    "    \n",
    "    # Variables to store the most similar and most dissimilar talks\n",
    "    most_similar_talk = None\n",
    "    most_dissimilar_talk = None\n",
    "    \n",
    "    highest_similarity = float('-inf')  # Initialize with a very low value\n",
    "    lowest_similarity = float('inf')    # Initialize with a very high value\n",
    "\n",
    "    # Loop through each saved embedding from the database\n",
    "    for talk in past_talks:\n",
    "        talk_embedding_str = talk[0]  # Extract the embedding as a string\n",
    "        talk_summary = talk[1]        # Extract the corresponding summary\n",
    "        \n",
    "        # Convert the embedding from a string back to a tensor\n",
    "        talk_embedding = torch.tensor(list(map(float, talk_embedding_str.split(','))))\n",
    "        \n",
    "        # Compute cosine similarity between the current query and the saved embeddings\n",
    "        similarity = util.pytorch_cos_sim(query_embedding, talk_embedding).item()\n",
    "        \n",
    "        # Check if this is the most similar talk so far\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            most_similar_talk = talk_summary\n",
    "        \n",
    "        # Check if this is the most dissimilar talk so far\n",
    "        if similarity < lowest_similarity:\n",
    "            lowest_similarity = similarity\n",
    "            most_dissimilar_talk = talk_summary\n",
    "    \n",
    "    # Return the summaries of the most similar and most dissimilar talks\n",
    "    return most_similar_talk, most_dissimilar_talk\n",
    "\n",
    "# Function to retrieve patient information from the database\n",
    "def get_patient_info(patient_id):\n",
    "    \n",
    "    # Connecting to SQL Server database\n",
    "    conn = open_db()\n",
    "    cursor = conn.cursor()   \n",
    "       \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT ID_Patient, Name, Date_of_birth, Sex, Additional_datas, Condition \n",
    "        FROM Patients \n",
    "        WHERE ID_Patient = ?\n",
    "    \"\"\", (patient_id,))\n",
    "    patient_info = cursor.fetchone()\n",
    "    \n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    if patient_info:\n",
    "        return {\n",
    "            \"ID_Patient\": patient_info[0],\n",
    "            \"Name\": patient_info[1],\n",
    "            \"Date_of_birth\": patient_info[2],\n",
    "            \"Sex\": patient_info[3],\n",
    "            \"Additional_datas\": patient_info[4],\n",
    "            \"Condition\": patient_info[5]\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to save the conversation data, including the embedding, into the database\n",
    "def save_talk(model, patient_id, text, summary, sentiment):\n",
    "    embedding = model.encode(summary, convert_to_tensor=True)\n",
    "    embedding_str = ','.join(map(str, embedding.tolist()))\n",
    "    \n",
    "    # Connecting to SQL Server database\n",
    "    conn = open_db()\n",
    "    cursor = conn.cursor()  \n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Talks (ID_Patient, Date_Time, Record, Summary, Sentiment, Embedding)\n",
    "        VALUES (?, GETDATE(), ?, ?, ?, ?)\n",
    "    \"\"\", (patient_id, text, summary, sentiment, embedding_str))\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "#You are psychologist, helping the Patient discuss their problems.\n",
    "# You are a Socratic questioner guiding someone through their thoughts and beliefs on a specific topic. Use open-ended questions to encourage deep thinking and self-reflection. Avoid giving direct answers or expressing opinions. Instead, focus on asking thoughtful questions that help clarify, probe assumptions, examine consequences, explore alternatives, and challenge ideas in a constructive way.\n",
    "# Start by asking the person to explain their thoughts on the topic and, through a series of follow-up questions, encourage them to delve deeper, analyze their reasoning, and consider different perspectives. For example, ask questions like:\n",
    "# \"Why do you think this is true or important?\"\n",
    "# \"What assumptions are you making here?\"\n",
    "# \"Can you think of another perspective on this?\"\n",
    "# \"What would happen if things were different?\"\n",
    "# \"How would you respond to someone with a contrary view?\"\n",
    "# Your goal is to stimulate critical thinking and insight, rather than to direct or persuade.\n",
    "\n",
    "# Function to generate a response using LLM and langchain-groq \n",
    "# For OpenIA model made fine-tuning as Psychologist\n",
    "def generate_response_llm(llm, session_record, previous_talk, similar_talk, dissimilar_talk, patient_info):\n",
    "    system_message = SystemMessage(content=f\"\"\"        \n",
    "        Speak russian.\n",
    "        \n",
    "        Patient information:\n",
    "            Name: {patient_info['Name']},\n",
    "            Date of birth: {patient_info['Date_of_birth']},\n",
    "            Sex: {patient_info['Sex']},\n",
    "            Additional data: {patient_info['Additional_datas']},\n",
    "            Condition: {patient_info['Condition']}.\n",
    "\n",
    "        Previous conversation with the Patient: {previous_talk or 'No previous conversation'}. \n",
    "        Summary of the most similar conversation with the Patient: {similar_talk or 'No similar conversation'}.\n",
    "        Summary of the most dissimilar conversation with the Patient: {dissimilar_talk or 'No dissimilar conversation'}.       \n",
    "    \"\"\")        \n",
    "    human_message = HumanMessage(content=f\"\"\"\n",
    "        Here is the current conversation record with the Patient: {session_record}.\n",
    "    \"\"\")\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([system_message, human_message])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling LLM: {e}\")      \n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Function to generate a summary at the end of the conversation\n",
    "def generate_summary(llm, session_record):\n",
    "    system_message = SystemMessage(content=\"You are a qualified psychologist. Create a brief summary of your conversation whith Patient.\")\n",
    "    human_message = HumanMessage(content=f\"Conversation: {session_record}.\")\n",
    "    \n",
    "    response = llm([system_message, human_message])\n",
    "    return response.content\n",
    "\n",
    "# Function to register a new patient\n",
    "def register_patient():\n",
    "    print(\"Patient not found. Please register.\")\n",
    "    name = input(\"Enter name: \")\n",
    "    date_of_birth = input(\"Enter date of birth (YYYY-MM-DD): \")\n",
    "    sex = input(\"Enter sex: \")\n",
    "    additional_data = input(\"Enter additional information if your want: \")\n",
    "    \n",
    "    # Connecting to SQL Server database\n",
    "    conn = open_db()\n",
    "    cursor = conn.cursor()  \n",
    "    # Insert new patient data into the Patients table and get the new ID\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Patients (Name, Date_of_birth, Sex, Additional_datas) \n",
    "        OUTPUT INSERTED.ID_Patient  -- Adjust this if your ID field has a different name\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", (name, date_of_birth, sex, additional_data))\n",
    "\n",
    "    # Fetch the ID of the new patient record\n",
    "    patient_id = cursor.fetchone()[0]  # Retrieves the first column of the first row\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()    \n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Patient registered with ID: {patient_id}\")\n",
    "    return patient_id\n",
    "\n",
    "\n",
    "# Main session process\n",
    "def main(patient_id):\n",
    "            \n",
    "    # Recording flag\n",
    "    global recording\n",
    "    recording = False\n",
    "    # Session finish flag\n",
    "    global finish_session   \n",
    "    finish_session = False\n",
    "\n",
    "    global llm, model\n",
    "    llm, model = import_llm_models()\n",
    "         \n",
    "    previous_talk = find_previous_talk(patient_id)\n",
    "\n",
    "    session_record = \"\"  \n",
    "    response_text = \"\"  \n",
    "\n",
    "    # Start a thread for session termination\n",
    "    threading.Thread(target=finish_session_function, daemon=True).start()\n",
    "\n",
    "    # Retrieve patient info\n",
    "    patient_info = get_patient_info(patient_id)\n",
    "    if not patient_info:\n",
    "        patient_id = register_patient()  # Register new patient\n",
    "        patient_info = get_patient_info(patient_id)  # Retrieve patient info again\n",
    "\n",
    "    print(f\"Starting session for: {patient_info['Name']}\")\n",
    "\n",
    "    Start_Talk = True\n",
    "    similar_talk = dissimilar_talk = \"\"\n",
    "\n",
    "    while True:        \n",
    "        patient_query, _ = recognize_speech()\n",
    "        if finish_session:  \n",
    "            print(\"Session ended.\")\n",
    "            summary = generate_summary(llm, session_record)\n",
    "            print(f\"Conversation summary: {summary}\")\n",
    "            save_talk(model, patient_id, session_record, summary, \"Neutral\")\n",
    "            break\n",
    "\n",
    "        session_record = update_session_record_query(patient_query, session_record)\n",
    "\n",
    "        if Start_Talk:\n",
    "            similar_talk, dissimilar_talk = find_similar_talks(llm, model, patient_id, session_record)\n",
    "            Start_Talk = False\n",
    "\n",
    "        # Pass patient info to LLM along with the conversation context\n",
    "        response_text = generate_response_llm(llm, session_record, previous_talk, similar_talk, dissimilar_talk, patient_info)\n",
    "        print(f\"Program response: {response_text}\")\n",
    "\n",
    "        session_record = update_session_record_response(response_text, session_record)\n",
    "\n",
    "        text_to_speech(response_text)\n",
    "\n",
    "# Entry point for the program\n",
    "if __name__ == \"__main__\":\n",
    "    patient_id = input(\"Enter patient ID: \")\n",
    "    main(patient_id)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
