{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for 'find_previous_talk': 0.0021  seconds.\n",
      "Execution time for 'get_patient_info': 0.0010  seconds.\n",
      "Starting session for: Ilya      \n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Recording. Speak...\n",
      "You said: жить хорошо\n",
      "Execution time for 'analyze_emotion': 0.0120  seconds.\n",
      "Emotion: calm\n",
      "Recording stopped.\n",
      "Execution time for 'generate_summary': 1.9009  seconds.\n",
      "Execution time for 'find_similar_talks': 1.9430  seconds.\n",
      "Execution time for 'generate_response_llm': 0.7305  seconds.\n",
      "Program response: Что, по вашему мнению, делает жизнь хорошей?\n",
      "Execution time for 'text_to_speech': 5.3543  seconds.\n",
      "Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\n",
      "Session ended.\n",
      "Execution time for 'generate_summary': 1.2484  seconds.\n",
      "Conversation summary: Summary: The patient expressed a positive sentiment about life, stating \"жить хорошо\" (life is good). The psychologist prompted further reflection by asking what specifically contributes to that positive perception, encouraging the patient to explore and articulate the factors that make life feel good to them.\n",
      "Execution time for 'update_patient_info': 0.8830  seconds.\n",
      "Execution time for 'save_talk': 0.0763  seconds.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import pyodbc\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import torch\n",
    "import keyboard\n",
    "import threading\n",
    "import time\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import time\n",
    "import functools\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def import_llm_models():\n",
    "    # API key for OpenAI\n",
    "    OPENAI_API_KEY = '...'\n",
    "    # Define LLM using OpenAI\n",
    "    llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"ft:gpt-4o-2024-08-06:personal:psychologist-1:APyJnbej\", temperature=0.5) #gpt-4o-2024-08-06 with fine tuning\n",
    "\n",
    "    # Model for generating text embeddings (very little Sentence-BERT model)\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    return llm, model\n",
    "\n",
    "def log_execution_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  \n",
    "        result = func(*args, **kwargs)  \n",
    "        end_time = time.time()  \n",
    "        execution_time = end_time - start_time  \n",
    "        print(f\"Execution time for '{func.__name__}': {execution_time:.4f}  seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def stop_recording():\n",
    "    global recording\n",
    "    keyboard.wait('f')  # Wait for the 'f' key press\n",
    "    time.sleep(0.1)  # Small delay before stopping recording\n",
    "    recording = False  # Set the recording flag to false\n",
    "\n",
    "def finish_session_function():\n",
    "    global finish_session\n",
    "    while not finish_session:\n",
    "        if keyboard.is_pressed('q'):  # Check for 'q' key press\n",
    "            finish_session = True  # Set the session finish flag\n",
    "        time.sleep(0.1)  # Short pause to reduce CPU load\n",
    "\n",
    "# Function to analyze emotion based on audio features\n",
    "@log_execution_time\n",
    "def analyze_emotion(audio_data, sr):\n",
    "    # Convert audio data to float32 and normalize\n",
    "    audio_data = audio_data.astype(np.float32) / np.max(np.abs(audio_data))\n",
    "    \n",
    "    # Extracting features\n",
    "    energy = np.mean(librosa.feature.rms(y=audio_data))\n",
    "    pitch, _ = librosa.piptrack(y=audio_data, sr=sr)\n",
    "    pitch_mean = np.mean(pitch[pitch > 0])\n",
    "\n",
    "    # Basic emotion classification (for demonstration purposes)\n",
    "    if energy > 0.1 and pitch_mean > 150:\n",
    "        emotion = \"excited\"\n",
    "    elif energy < 0.05:\n",
    "        emotion = \"calm\"\n",
    "    elif pitch_mean < 120:\n",
    "        emotion = \"scared\"\n",
    "    else:\n",
    "        emotion = \"neutral\"\n",
    "\n",
    "    return emotion\n",
    "\n",
    "# Speech recognition function with emotion analysis\n",
    "def recognize_speech():\n",
    "    global recording, finish_session\n",
    "    patient_query = \"\"\n",
    "    r = sr.Recognizer()\n",
    "    print(\"Press 's' to start recording, 'f' to stop recording. Press 'q' to end the session.\")\n",
    "\n",
    "    while not finish_session:\n",
    "        if keyboard.is_pressed('s') and not recording:  # Start recording on 's' key press\n",
    "            recording = True\n",
    "            print(\"Recording. Speak...\")\n",
    "            threading.Thread(target=stop_recording, daemon=True).start()  # Thread to stop recording\n",
    "\n",
    "        if recording:  # Recording is active\n",
    "            with sr.Microphone() as source:\n",
    "                r.adjust_for_ambient_noise(source)\n",
    "                full_text = []\n",
    "\n",
    "                while recording and not finish_session:\n",
    "                    try:\n",
    "                        audio = r.listen(source, timeout=None)\n",
    "                        text = r.recognize_google(audio, language=\"ru-RU\")\n",
    "                        print(f\"You said: {text}\")\n",
    "                        full_text.append(text)\n",
    "                        \n",
    "                        # Convert to audio array for emotion analysis\n",
    "                        audio_data = np.frombuffer(audio.get_raw_data(), np.int16)\n",
    "                        emotion = analyze_emotion(audio_data, source.SAMPLE_RATE)\n",
    "                        print(f\"Emotion: {emotion}\")\n",
    "\n",
    "                    except sr.UnknownValueError:\n",
    "                        print(\"Could not understand the audio. Please speak clearly.\")\n",
    "                    except sr.RequestError as e:\n",
    "                        print(f\"Service error; {e}\")\n",
    "                        break\n",
    "\n",
    "                print(\"Recording stopped.\")\n",
    "                recording = False\n",
    "                patient_query = ' '.join(full_text)\n",
    "                return patient_query, emotion  # Return recognized text with emotion\n",
    "    \n",
    "    return patient_query, \"No emotion detected\"  # Default return in case of session end\n",
    "\n",
    "# Function to generate an audio response\n",
    "@log_execution_time\n",
    "def text_to_speech(text):\n",
    "    tts = gTTS(text=text, lang='ru')  # Changed 'ru' to 'en'\n",
    "    tts.save(\"response.mp3\")\n",
    "    audio = AudioSegment.from_mp3(\"response.mp3\")\n",
    "    play(audio)\n",
    "\n",
    "\n",
    "# Function to find the most recent completed conversation (previous_talk)\n",
    "@log_execution_time\n",
    "def find_previous_talk(patient_id, cursor):\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT TOP 1 Record FROM Talks\n",
    "        WHERE ID_Patient = ? \n",
    "        ORDER BY Date_Time DESC\n",
    "    \"\"\", (patient_id,))\n",
    "    previous_talk = cursor.fetchone()\n",
    "\n",
    "    return previous_talk[0] if previous_talk else \"\"\n",
    "\n",
    "# Function to update the session record with patient query\n",
    "def update_session_record_query(patient_query, session_record):\n",
    "    session_record += f\"Patient said: {patient_query}. \"    \n",
    "    return session_record\n",
    "\n",
    "# Function to update the session record with program response\n",
    "def update_session_record_response(program_response, session_record):\n",
    "    session_record += f\"Psychologist responded: {program_response}. \"\n",
    "    return session_record\n",
    "\n",
    "# Function to find the most similar and most dissimilar conversations 2.2015  seconds\n",
    "@log_execution_time\n",
    "def find_similar_talks(llm, model, patient_id, query, cursor):        \n",
    "     \n",
    "    # Fetch all embeddings and summaries for the given patient from the database\n",
    "    cursor.execute(\"SELECT Embedding, Summary FROM Talks WHERE ID_Patient = ?\", (patient_id,))\n",
    "    past_talks = cursor.fetchall()\n",
    "    \n",
    "    # Generate the embedding for the current query\n",
    "    query_s = generate_summary(llm, query)\n",
    "    query_embedding = model.encode(query_s, convert_to_tensor=True)\n",
    "    \n",
    "    # Variables to store the most similar and most dissimilar talks\n",
    "    most_similar_talk = None\n",
    "    most_dissimilar_talk = None\n",
    "    \n",
    "    highest_similarity = float('-inf')  # Initialize with a very low value\n",
    "    lowest_similarity = float('inf')    # Initialize with a very high value\n",
    "\n",
    "    # Loop through each saved embedding from the database\n",
    "    for talk in past_talks:\n",
    "        talk_embedding_str = talk[0]  # Extract the embedding as a string\n",
    "        talk_summary = talk[1]        # Extract the corresponding summary\n",
    "        \n",
    "        # Convert the embedding from a string back to a tensor\n",
    "        talk_embedding = torch.tensor(list(map(float, talk_embedding_str.split(','))))\n",
    "        \n",
    "        # Compute cosine similarity between the current query and the saved embeddings\n",
    "        similarity = util.pytorch_cos_sim(query_embedding, talk_embedding).item()\n",
    "        \n",
    "        # Check if this is the most similar talk so far\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            most_similar_talk = talk_summary\n",
    "        \n",
    "        # Check if this is the most dissimilar talk so far\n",
    "        if similarity < lowest_similarity:\n",
    "            lowest_similarity = similarity\n",
    "            most_dissimilar_talk = talk_summary\n",
    "    \n",
    "    # Return the summaries of the most similar and most dissimilar talks\n",
    "    return most_similar_talk, most_dissimilar_talk\n",
    "\n",
    "# Function to retrieve patient information from the database\n",
    "@log_execution_time\n",
    "def get_patient_info(patient_id, cursor):\n",
    "       \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT ID_Patient, Name, Date_of_birth, Sex, Additional_datas, Condition \n",
    "        FROM Patients \n",
    "        WHERE ID_Patient = ?\n",
    "    \"\"\", (patient_id,))\n",
    "    patient_info = cursor.fetchone()\n",
    "    \n",
    "    if patient_info:\n",
    "        return {\n",
    "            \"ID_Patient\": patient_info[0],\n",
    "            \"Name\": patient_info[1],\n",
    "            \"Date_of_birth\": patient_info[2],\n",
    "            \"Sex\": patient_info[3],\n",
    "            \"Additional_datas\": patient_info[4],\n",
    "            \"Condition\": patient_info[5]\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to generate a response using LLM and langchain-groq. For OpenIA model made fine-tuning as Psychologist\n",
    "@log_execution_time \n",
    "def generate_response_llm(llm, session_record, previous_talk, similar_talk, dissimilar_talk, patient_info, emotion):\n",
    "    system_message = SystemMessage(content=f\"\"\"        \n",
    "        Speak russian.\n",
    "        \n",
    "        Patient information:\n",
    "            Name: {patient_info['Name']},\n",
    "            Date of birth: {patient_info['Date_of_birth']},\n",
    "            Sex: {patient_info['Sex']},\n",
    "            Additional data: {patient_info['Additional_datas']},\n",
    "            Condition: {patient_info['Condition']}.\n",
    "\n",
    "        Previous conversation with the Patient: {previous_talk or 'No previous conversation'}. \n",
    "        Summary of the most similar conversation with the Patient: {similar_talk or 'No similar conversation'}.\n",
    "        Summary of the most dissimilar conversation with the Patient: {dissimilar_talk or 'No dissimilar conversation'}. \n",
    "        Pay attention to the emotional analysis of speech: {emotion or 'No emotion detected'}      \n",
    "    \"\"\")        \n",
    "    human_message = HumanMessage(content=f\"\"\"\n",
    "        Here is the current conversation record with the Patient: {session_record}.\n",
    "    \"\"\")\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([system_message, human_message])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling LLM: {e}\")      \n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Function to generate a summary at the end of the conversation\n",
    "@log_execution_time\n",
    "def generate_summary(llm, session_record):\n",
    "    system_message = SystemMessage(content=\"You are a qualified psychologist. Create a brief summary of your conversation whith Patient.\")\n",
    "    human_message = HumanMessage(content=f\"Conversation: {session_record}.\")\n",
    "    \n",
    "    response = llm([system_message, human_message])\n",
    "    return response.content\n",
    "\n",
    "# Function extracts facts about the patient from his conversation and updates the collected data about him\n",
    "@log_execution_time\n",
    "def update_patient_info(llm, session_record, patient_info): \n",
    "    system_message = SystemMessage(content=f\"\"\"        \n",
    "        Review the current conversation transcript and update the 'Additional_datas' field with new facts about the patient, if any: {patient_info['Additional_datas']}.        \n",
    "    \"\"\") \n",
    "    human_message = HumanMessage(content=f\"Here is the current conversation record with the Patient: {session_record}\")\n",
    "    \n",
    "    # Call the model to update additional_data\n",
    "    updated_additional_datas = llm([system_message, human_message])\n",
    "    \n",
    "    # Update additional_datas field using model response\n",
    "    patient_info['Additional_datas'] = updated_additional_datas.content.strip()\n",
    "    \n",
    "    return patient_info\n",
    "\n",
    "\n",
    "# Function to save the conversation data, including the embedding, updates Additional_datas into the database\n",
    "@log_execution_time\n",
    "def save_talk(model, patient_id, text, summary, sentiment, patient_info, cursor):\n",
    "    embedding = model.encode(summary, convert_to_tensor=True)\n",
    "    embedding_str = ','.join(map(str, embedding.tolist()))\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Talks (ID_Patient, Date_Time, Record, Summary, Sentiment, Embedding)\n",
    "        VALUES (?, GETDATE(), ?, ?, ?, ?)\n",
    "    \"\"\", (patient_id, text, summary, sentiment, embedding_str))\n",
    "\n",
    "    Additional_datas = patient_info['Additional_datas']  \n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        UPDATE Patients\n",
    "        SET Additional_datas = ?\n",
    "        WHERE ID_Patient = ?\n",
    "    \"\"\", (Additional_datas, patient_id)) \n",
    "    \n",
    "\n",
    "# Function to register a new patient\n",
    "def register_patient(cursor):\n",
    "    print(\"Patient not found. Please register.\")\n",
    "    name = input(\"Enter name: \")\n",
    "    date_of_birth = input(\"Enter date of birth (YYYY-MM-DD): \")\n",
    "    sex = input(\"Enter sex: \")\n",
    "    additional_data = input(\"Enter additional information if your want: \")    \n",
    " \n",
    "    # Insert new patient data into the Patients table and get the new ID\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Patients (Name, Date_of_birth, Sex, Additional_datas) \n",
    "        OUTPUT INSERTED.ID_Patient  -- Adjust this if your ID field has a different name\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", (name, date_of_birth, sex, additional_data))\n",
    "\n",
    "    # Fetch the ID of the new patient record\n",
    "    patient_id = cursor.fetchone()[0]  # Retrieves the first column of the first row\n",
    "   \n",
    "    print(f\"Patient registered with ID: {patient_id}\")\n",
    "    return patient_id\n",
    "\n",
    "# Connecting to SQL Server database\n",
    "class DatabaseConnection:\n",
    "    def __enter__(self):        \n",
    "        self.conn = pyodbc.connect(\n",
    "            'DRIVER={SQL Server};'\n",
    "            'SERVER=DESKTOP-SPMU70G\\\\SQLEXPRESS;'\n",
    "            'DATABASE=Psychologist;'\n",
    "            'UID=DESKTOP-SPMU70G\\\\domashniy;'\n",
    "            'Trusted_Connection=yes;'\n",
    "        )\n",
    "        self.cursor = self.conn.cursor()\n",
    "        return self.conn, self.cursor\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.conn.commit()\n",
    "        self.conn.close()\n",
    "\n",
    "def main(patient_id):\n",
    "    global recording, finish_session, llm, model\n",
    "    recording = False\n",
    "    finish_session = False\n",
    "    llm, model = import_llm_models()\n",
    "\n",
    "    session_record = \"\"\n",
    "    response_text = \"\"\n",
    "\n",
    "    # Using DatabaseConnection as a context manager\n",
    "    with DatabaseConnection() as (conn, cursor):\n",
    "        previous_talk = find_previous_talk(patient_id, cursor)\n",
    "\n",
    "        # Start a thread to monitor session termination\n",
    "        threading.Thread(target=finish_session_function, daemon=True).start()\n",
    "\n",
    "        patient_info = get_patient_info(patient_id, cursor)\n",
    "        if not patient_info:\n",
    "            patient_id = register_patient(cursor)\n",
    "            patient_info = get_patient_info(patient_id, cursor)\n",
    "\n",
    "        print(f\"Starting session for: {patient_info['Name']}\")\n",
    "\n",
    "        Start_Talk = True\n",
    "        similar_talk = dissimilar_talk = \"\"\n",
    "\n",
    "        while True:\n",
    "            patient_query, emotion = recognize_speech()\n",
    "            if finish_session:\n",
    "                print(\"Session ended.\")\n",
    "                summary = generate_summary(llm, session_record)\n",
    "                print(f\"Conversation summary: {summary}\")\n",
    "                update_patient_info(llm, session_record, patient_info)\n",
    "                save_talk(model, patient_id, session_record, summary, \"Neutral\", patient_info, cursor)\n",
    "                break\n",
    "\n",
    "            session_record = update_session_record_query(patient_query, session_record)\n",
    "\n",
    "            if Start_Talk:\n",
    "                similar_talk, dissimilar_talk = find_similar_talks(\n",
    "                    llm, model, patient_id, session_record, cursor\n",
    "                )\n",
    "                Start_Talk = False\n",
    "\n",
    "            response_text = generate_response_llm(\n",
    "                llm, session_record, previous_talk, similar_talk, dissimilar_talk, patient_info, emotion\n",
    "            )\n",
    "            print(f\"Program response: {response_text}\")\n",
    "\n",
    "            session_record = update_session_record_response(response_text, session_record)\n",
    "\n",
    "            text_to_speech(response_text)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    patient_id = input(\"Enter patient ID: \")\n",
    "    main(patient_id)\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
